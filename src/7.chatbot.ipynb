{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended conversations while following up the topic\n",
    "\n",
    "You might have noticed, the openAI ChatCompletion api takes an array of messages. So far we've been passing only 1 message (the prompt) with role: \"user\".\n",
    "It can be a sequence of messages of a conversation, so that the model can have a context of previous discussions, and continue the\n",
    "\n",
    "This notebook explores how we can create personalized or specialized ChatBots for specific tasks or behaviors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import necessary libraries and load openAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to get GPT response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old function, that takes 1 msg as prompt and responds. It doesn't have any record of previous conversations\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=temperature, # this is the degree of randomness of the model's output\n",
    "  )\n",
    "  return response.choices[0].message[\"content\"]\n",
    "\n",
    "# New function takes a messages array\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=temperature, # this is the degree of randomness of the model's output\n",
    "  )\n",
    "  # print(str(response.choices[0].message))\n",
    "  return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roles for messages\n",
    "- system: What kind of bot it is, A personality\n",
    "- assistant: Responder from the system, carrying the system's personality\n",
    "- user: User who is interacting with the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [\n",
    "  # Defining the personality of the Chat-Bot\n",
    "  { 'role':'system', 'content':'You are an assistant that speaks like Shakespeare.' },\n",
    "  # Conversation so far...\n",
    "  { 'role':'user', 'content':'tell me a joke' },\n",
    "  { 'role':'assistant', 'content':'Why did the chicken cross the road' },\n",
    "  { 'role':'user', 'content':'I don\\'t know' }\n",
    "]\n",
    "\n",
    "# bot will continue the conversation with an answer with the role: assistant\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "  { 'role':'system', 'content':'You are friendly chatbot.' },\n",
    "  { 'role':'user', 'content':'Hi, my name is Isa' }\n",
    "]\n",
    "\n",
    "# friendly chatbot will respond with a greeting\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "  { 'role':'system', 'content':'You are friendly chatbot.' },\n",
    "  { 'role':'user', 'content':'Yes, can you remind me, What is my name?' }\n",
    "]\n",
    "\n",
    "# Here the friendly chat-bot doesn't have any context for the given prompt.\n",
    "# Of course it doesn't know the user's name, we never told it. It's going to respond with an error\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "  { 'role':'system', 'content':'You are friendly chatbot.' },\n",
    "  { 'role':'user', 'content':'Hi, my name is Isa' },\n",
    "  { 'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. Is there anything I can help you with today?\" },\n",
    "  { 'role':'user', 'content':'Yes, you can remind me, What is my name?' }\n",
    "]\n",
    "\n",
    "# This time the bot has context, the user has provided their name previously. The bot can answer\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Bot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the chatbot Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_persona = \"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant.\n",
    "You first greet the customer, then collects the order, and then asks if it's a\n",
    "pickup or delivery. You wait to collect the entire order, then summarize it \n",
    "and check for a final time if the customer wants to add anything else. \n",
    "If it's a delivery, you ask for an address. Finally you collect the payment.\n",
    "Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.\n",
    "You respond in a short, very conversational friendly style.\n",
    "\n",
    "The menu includes \n",
    "pepperoni pizza  12.95, 10.00, 7.00\n",
    "cheese pizza   10.95, 9.25, 6.50\n",
    "eggplant pizza   11.95, 9.75, 6.75\n",
    "fries 4.50, 3.50\n",
    "greek salad 7.25\n",
    "\n",
    "Toppings:\n",
    "extra cheese 2.00,\n",
    "mushrooms 1.50\n",
    "sausage 3.00\n",
    "canadian bacon 3.50\n",
    "AI sauce 1.50\n",
    "peppers 1.00\n",
    "\n",
    "Drinks:\n",
    "coke 3.00, 2.00, 1.00\n",
    "sprite 3.00, 2.00, 1.00\n",
    "bottled water 5.00\n",
    "\"\"\"\n",
    "\n",
    "context = [{ 'role':'system', 'content': system_persona }]  # We'll accumulate messages in this context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Chat-UI for placing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn # GUI\n",
    "\n",
    "pn.extension()\n",
    "# input box for the user to type msg\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text hereâ€¦')\n",
    "# Send button\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "# We'll add assistant response and user msgs of the conversation between them.\n",
    "panels = [] # collect display \n",
    "\n",
    "def collect_messages(_):\n",
    "  # collect the user msg\n",
    "  prompt = inp.value_input\n",
    "  # reset input box\n",
    "  inp.value = ''\n",
    "  # Append user msg\n",
    "  context.append({ 'role':'user', 'content':f\"{prompt}\" })\n",
    "  # get response\n",
    "  response = get_completion_from_messages(context) \n",
    "  # append bot response\n",
    "  context.append({ 'role':'assistant', 'content':f\"{response}\" })\n",
    "  # Append the msgs to UI\n",
    "  panels.append(\n",
    "    pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "  panels.append(\n",
    "    pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    "\n",
    "  return pn.Column(*panels)\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "  inp,\n",
    "  pn.Row(button_conversation),\n",
    "  pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "# Render the Chat UI with msgs\n",
    "dashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate JSON object for the order details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  context.copy()\n",
    "messages.append(\n",
    "{\n",
    "  'role':'system', \n",
    "  'content':\"\"\"\n",
    "  create a json summary of the previous food order. \n",
    "  Itemize the price for each item The fields should be \n",
    "    1) pizza, include size \n",
    "    2) list of toppings \n",
    "    3) list of drinks, include size   \n",
    "    4) list of sides include size  \n",
    "    5)total price\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "# The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
